{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "feature_vector_folder = ''\n",
    "densenet_features_files = glob(feature_vector_folder+'/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_values = []\n",
    "file_names = []\n",
    "for feature_file in densenet_features_files:\n",
    "    with open(feature_file,\"r\") as file:\n",
    "        feature_dictionary = json.loads(file.read())\n",
    "    \n",
    "    feature_values = feature_values + [np.array(list(feature_dictionary.values()))]\n",
    "    file_names = file_names + [np.array(list(feature_dictionary.keys()))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "file_list = []\n",
    "i = 0\n",
    "for folder in feature_values:\n",
    "    for file in folder:\n",
    "        feature_list = feature_list + [file]\n",
    "    i = i + 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = faiss.PCAMatrix (1024, 500)\n",
    "mat.train(np.array(feature_list).astype('float32'))\n",
    "assert mat.is_trained\n",
    "feature_values_transformed = mat.apply(np.array(feature_list).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncentroids = 20\n",
    "niter = 20\n",
    "verbose = True\n",
    "kmeans = faiss.Kmeans(feature_values_transformed.shape[1], ncentroids, niter=niter, verbose=verbose)\n",
    "kmeans.train(feature_values_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = kmeans.index.search(feature_values_transformed, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = feature_values_transformed.shape[1]\n",
    "index = faiss.IndexFlatL2 (d)\n",
    "index.add (feature_values_transformed)\n",
    "D_c, I_c = index.search (kmeans.centroids, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(file_list,columns = ['filename'])\n",
    "data_frame['Cluster'] = I\n",
    "data_frame['Distance'] = D\n",
    "data_frame.to_csv('/mnt/largedrive0/katariap/feature_extraction/data/Dataset/Clusters_densenet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for i in range(len(file_list)):\n",
    "    \n",
    "    if (I[i] not in list(clusters.keys())):\n",
    "        \n",
    "        clusters[I[i][0]] = [file_list[i]]\n",
    "    else:\n",
    "        clusters[I[i][0]] = clusters[I[i][0]] + [file_list[i]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in range(ncentroids):\n",
    "\n",
    "        fig = plt.figure(figsize = (30,30))\n",
    "        files = clusters[number]\n",
    "\n",
    "        if len(files) > 10:\n",
    "            files = random.sample(files,10)\n",
    "        for index,file in enumerate(files):\n",
    "            plt.subplot(5,5,index+1)\n",
    "            name = file.split('/')[-1]\n",
    "            img = Image.open(file)\n",
    "            img = np.array(img)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(name ,fontsize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "cluster_file = '/mnt/largedrive0/katariap/feature_extraction/data/Dataset/clusters.pickle'\n",
    "with open(cluster_file,'rb') as data_file:\n",
    "    clusters = pickle.load(data_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "selected_clusters = [1,2,4,6,7,8,9,10,11,12,13,17,18,19]\n",
    "for i in selected_clusters:\n",
    "    final_list = final_list + clusters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_patches = pd.DataFrame(final_list, columns = ['Patch'])\n",
    "selected_patches.to_csv('/mnt/largedrive0/katariap/feature_extraction/data/Dataset/selected_after_clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/largedrive0/katariap/feature_extraction/data/Dataset/clusters.pickle', 'wb') as file:\n",
    "    pickle.dump(clusters, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
